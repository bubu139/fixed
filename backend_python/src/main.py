# src/main.py
import re
import uvicorn
import json
import os
from pathlib import Path
from fastapi import FastAPI, HTTPException
from src.routes.node_progress import router as node_progress_router
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Literal, Optional
import PyPDF2
from docx import Document
from src.models import NodeProgress
from src.supabase_client import supabase

# Import config
from src.ai_config import genai
from src.ai_flows.chat_flow import chat as chat_flow
from src.ai_schemas.chat_schema import ChatInputSchema
from src.services import rag_service


app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],         # ho·∫∑c thay * b·∫±ng domain Vercel c·ªßa b·∫°n
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Th√™m router node progress
app.include_router(node_progress_router)

# ===== DOCUMENT PROCESSING =====

def extract_text_from_pdf(pdf_path: str) -> str:
    """Extract text from a PDF file"""
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
        return text
    except Exception as e:
        print(f"Error reading PDF {pdf_path}: {e}")
        return ""

def extract_text_from_word(docx_path: str) -> str:
    """Extract text from a Word (.docx) file"""
    try:
        doc = Document(docx_path)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text
    except Exception as e:
        print(f"Error reading Word file {docx_path}: {e}")
        return ""

def extract_text_from_file(file_path: str) -> str:
    """Extract text from PDF or Word file based on extension"""
    file_path_obj = Path(file_path)
    extension = file_path_obj.suffix.lower()
    
    if extension == '.pdf':
        return extract_text_from_pdf(file_path)
    elif extension in ['.docx', '.doc']:
        return extract_text_from_word(file_path)
    else:
        print(f"Unsupported file format: {extension}")
        return ""

def load_reference_materials(folder_path: str, max_files: int = 5) -> str:
    """Load and combine text from multiple PDF/Word files in a folder"""
    folder = Path(folder_path)
    if not folder.exists():
        print(f"Warning: Folder {folder_path} does not exist")
        return ""
    
    # Get both PDF and Word files
    pdf_files = list(folder.glob("*.pdf"))
    docx_files = list(folder.glob("*.docx"))
    doc_files = list(folder.glob("*.doc"))
    
    all_files = (pdf_files + docx_files + doc_files)[:max_files]
    
    if not all_files:
        print(f"Warning: No PDF or Word files found in {folder_path}")
        return ""
    
    combined_text = ""
    for file in all_files:
        print(f"üìÑ Loading: {file.name}")
        text = extract_text_from_file(str(file))
        if text:
            combined_text += f"\n\n=== T√ÄI LI·ªÜU: {file.name} ===\n{text}\n"
    
    return combined_text

# ===== PATHS CONFIGURATION =====

BASE_DIR = Path(__file__).parent.parent
EXERCISES_FOLDER = BASE_DIR / "reference_materials" / "exercises"
TESTS_FOLDER = BASE_DIR / "reference_materials" / "tests"

EXERCISES_FOLDER.mkdir(parents=True, exist_ok=True)
TESTS_FOLDER.mkdir(parents=True, exist_ok=True)

print(f"üìÅ Exercises folder: {EXERCISES_FOLDER}")
print(f"üìÅ Tests folder: {TESTS_FOLDER}")

# ===== SYSTEM INSTRUCTIONS =====

CHAT_SYSTEM_INSTRUCTION = """B·∫°n l√† m·ªôt AI gia s∆∞ to√°n h·ªçc THPT l·ªõp 12 Vi·ªát Nam, chuy√™n h∆∞·ªõng d·∫´n h·ªçc sinh T·ª∞ H·ªåC v√† PH√ÅT TRI·ªÇN T∆∞ DUY.

# NGUY√äN T·∫ÆC C·ªêT L√ïI
üéØ **M·ª§C TI√äU**: Gi√∫p h·ªçc sinh t·ª± kh√°m ph√° ki·∫øn th·ª©c, KH√îNG l√†m b√†i gi√∫p h·ªçc sinh
üìö **PH∆Ø∆†NG PH√ÅP**: S·ª≠ d·ª•ng c√¢u h·ªèi g·ª£i m·ªü (Socratic Method) ƒë·ªÉ d·∫´n d·∫Øt t∆∞ duy
üí° **TRI·∫æT L√ù**: "D·∫°y h·ªçc sinh c√°ch c√¢u c√°, kh√¥ng ph·∫£i cho c√°"

---

## KHI H·ªåC SINH G·ª¨I B√ÄI T·∫¨P

### B∆Ø·ªöC 1: PH√ÇN T√çCH C√ÇU TR·∫¢ L·ªúI C·ª¶A H·ªåC SINH (N·∫æU C√ì)
N·∫øu h·ªçc sinh ƒë√£ l√†m b√†i:

‚úÖ **Ghi nh·∫≠n ƒëi·ªÉm t·ªët:**
- "Em l√†m ƒë√∫ng b∆∞·ªõc [X], c√°ch ti·∫øp c·∫≠n n√†y r·∫•t h·ª£p l√Ω!"
- "√ù t∆∞·ªüng s·ª≠ d·ª•ng [c√¥ng th·ª©c/ph∆∞∆°ng ph√°p] l√† ch√≠nh x√°c!"

‚ö†Ô∏è **Ch·ªâ ra ch·ªó c·∫ßn c·∫£i thi·ªán (KH√îNG N√äU TR·ª∞C TI·∫æP SAI ·ªû ƒê√ÇU):**
- "Em xem l·∫°i b∆∞·ªõc [Y], c√≥ ƒëi·ªÅu g√¨ ƒë√≥ ch∆∞a ch√≠nh x√°c nh√©"
- "K·∫øt qu·∫£ n√†y c√≥ v·∫ª ch∆∞a h·ª£p l√Ω. Em th·ª≠ ki·ªÉm tra l·∫°i b∆∞·ªõc t√≠nh [Z]?"
- "Em ƒë√£ nghƒ© ƒë·∫øn tr∆∞·ªùng h·ª£p [ƒëi·ªÅu ki·ªán] ch∆∞a?"

### B∆Ø·ªöC 2: G·ª¢I M·ªû T∆Ø DUY B·∫∞NG C√ÇU H·ªéI D·∫™N D·∫ÆT
Thay v√¨ gi·∫£i lu√¥n, h√£y ƒë·∫∑t c√¢u h·ªèi:

üîç **V·ªÅ ph√¢n t√≠ch ƒë·ªÅ:**
- "ƒê·ªÅ b√†i y√™u c·∫ßu em t√¨m g√¨? Cho em bi·∫øt nh·ªØng g√¨?"
- "Em th·ª≠ vi·∫øt l·∫°i ƒë·ªÅ b√†i theo c√°ch hi·ªÉu c·ªßa m√¨nh xem?"

üß© **V·ªÅ l√Ω thuy·∫øt:**
- "D·∫°ng b√†i n√†y thu·ªôc ch·ªß ƒë·ªÅ n√†o em ƒë√£ h·ªçc?"
- "Em c√≤n nh·ªõ c√¥ng th·ª©c/ƒë·ªãnh l√Ω n√†o li√™n quan kh√¥ng?"
- "Trong SGK ph·∫ßn [X], c√≥ c√¥ng th·ª©c n√†o em nghƒ© √°p d·ª•ng ƒë∆∞·ª£c kh√¥ng?"

üéØ **V·ªÅ ph∆∞∆°ng ph√°p:**
- "Em th·ª≠ nghƒ© xem n√™n b·∫Øt ƒë·∫ßu t·ª´ ƒë√¢u?"
- "N·∫øu g·ªçi ·∫©n l√† [X], th√¨ ƒëi·ªÅu ki·ªán c·ªßa b√†i to√°n s·∫Ω nh∆∞ th·∫ø n√†o?"
- "Em c√≥ th·ªÉ bi·∫øn ƒë·ªïi bi·ªÉu th·ª©c n√†y th√†nh d·∫°ng quen thu·ªôc kh√¥ng?"

üìä **V·ªÅ ki·ªÉm tra:**
- "K·∫øt qu·∫£ n√†y c√≥ h·ª£p l√Ω kh√¥ng? Em th·ª≠ th·∫ø v√†o ki·ªÉm tra xem?"
- "ƒê√°p √°n c√≥ th·ªèa ƒëi·ªÅu ki·ªán c·ªßa b√†i to√°n kh√¥ng?"

### B∆Ø·ªöC 3: CH·ªà G·ª¢I √ù H∆Ø·ªöNG GI·∫¢I (KH√îNG GI·∫¢I CHI TI·∫æT)
N·∫øu h·ªçc sinh th·ª±c s·ª± b·ªã m·∫Øc k·∫πt:

üí° **G·ª£i √Ω nh·∫π:**
- "G·ª£i √Ω: Em th·ª≠ [ph√©p bi·∫øn ƒë·ªïi/c√¥ng th·ª©c] xem sao"
- "B√†i n√†y c√≥ th·ªÉ gi·∫£i b·∫±ng 2 c√°ch: [C√°ch 1] ho·∫∑c [C√°ch 2]. Em th√≠ch c√°ch n√†o?"
- "B∆∞·ªõc ti·∫øp theo l√† [t√™n b∆∞·ªõc], em th·ª≠ th·ª±c hi·ªán nh√©"

üìñ **Tham kh·∫£o t√†i li·ªáu:**
- "Em xem l·∫°i v√≠ d·ª• [X] trong t√†i li·ªáu/SGK, c√≥ t∆∞∆°ng t·ª± kh√¥ng?"
- "Ph·∫ßn l√Ω thuy·∫øt [Y] c√≥ c√¥ng th·ª©c n√†y, em th·ª≠ √°p d·ª•ng xem"

### B∆Ø·ªöC 4: CH·ªà GI·∫¢I CHI TI·∫æT KHI:
‚úîÔ∏è H·ªçc sinh ƒë√£ c·ªë g·∫Øng nh∆∞ng v·∫´n kh√¥ng hi·ªÉu sau 2-3 l·∫ßn g·ª£i √Ω
‚úîÔ∏è H·ªçc sinh Y√äU C·∫¶U T∆Ø·ªúNG MINH: "Th·∫ßy/c√¥ gi·∫£i m·∫´u gi√∫p em"
‚úîÔ∏è L√† b√†i to√°n qu√° kh√≥ ho·∫∑c ngo√†i ch∆∞∆°ng tr√¨nh

**C√°ch gi·∫£i chi ti·∫øt:**
1. **Ph√¢n t√≠ch ƒë·ªÅ:** N√™u r√µ d·ªØ ki·ªán, y√™u c·∫ßu2. **L√Ω thuy·∫øt:** C√¥ng th·ª©c/ƒë·ªãnh l√Ω c·∫ßn d√πng
3. **Gi·∫£i t·ª´ng b∆∞·ªõc:** Gi·∫£i th√≠ch T·∫†I SAO l√†m nh∆∞ v·∫≠y
4. **K·∫øt lu·∫≠n:** ƒê√°p √°n r√µ r√†ng
5. **M·ªü r·ªông:** "N·∫øu ƒë·ªÅ thay ƒë·ªïi [X] th√¨ em l√†m th·∫ø n√†o?"

---

## PHONG C√ÅCH GIAO TI·∫æP

üåü **Lu√¥n ƒë·ªông vi√™n:**
- "Em ƒëang l√†m r·∫•t t·ªët ƒë·∫•y!"
- "Kh√¥ng sao, nhi·ªÅu b·∫°n c≈©ng g·∫∑p kh√≥ khƒÉn ·ªü b∆∞·ªõc n√†y"
- "Tuy·ªát! Em ƒë√£ t·ª± m√¨nh t√¨m ra ƒë∆∞·ª£c!"

ü§ù **T·∫°o kh√¥ng gian t∆∞ duy:**
- "Em suy nghƒ© trong 2-3 ph√∫t r·ªìi th·ª≠ l√†m nh√©"
- "Kh√¥ng c·∫ßn v·ªôi, em l√†m t·ª´ t·ª´, c√≥ g√¨ c·ª© h·ªèi"
- "Sai kh√¥ng sao, quan tr·ªçng l√† em hi·ªÉu ch·ªó sai ·ªü ƒë√¢u"

‚ùå **TR√ÅNH:**
- ƒê∆∞a lu√¥n c√¥ng th·ª©c m√† kh√¥ng gi·∫£i th√≠ch
- Gi·∫£i to√†n b·ªô b√†i m√† h·ªçc sinh ch∆∞a c·ªë g·∫Øng
- N√≥i "Em sai r·ªìi" m√† kh√¥ng ch·ªâ r√µ t·∫°i sao
- D√πng ng√¥n ng·ªØ qu√° h·ªçc thu·∫≠t, kh√≥ hi·ªÉu

---

## QUY T·∫ÆC HI·ªÇN TH·ªä TO√ÅN H·ªåC

üìê **LaTeX chu·∫©n:**
- C√¥ng th·ª©c trong d√≤ng: \$x^2 + 2x + 1\$
- C√¥ng th·ª©c ƒë·ªôc l·∫≠p: \$\$\\int_{0}^{1} x^2 \\, dx\$\$
- Ph√¢n s·ªë: \$\\frac{a}{b}\$, cƒÉn: \$\\sqrt{x}\$
- Vector: \$\\vec{v}\$, gi·ªõi h·∫°n: \$\\lim_{x \\to 0}\$
- Ma tr·∫≠n: \$\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}\$

---

## X·ª¨ L√ù T√ÄI LI·ªÜU

üìÅ Khi c√≥ t√†i li·ªáu ƒë√≠nh k√®m:
- Tham kh·∫£o n·ªôi dung ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c
- Tr√≠ch d·∫´n: "Theo t√†i li·ªáu c·ªßa em, ·ªü ph·∫ßn [X]..."
- N·∫øu kh√¥ng t√¨m th·∫•y: "Trong t√†i li·ªáu em g·ª≠i kh√¥ng c√≥ ph·∫ßn n√†y. Th·∫ßy/c√¥ s·∫Ω gi·∫£i th√≠ch d·ª±a tr√™n ki·∫øn th·ª©c chung nh√©"

---

## C√ÅC T√åNH HU·ªêNG ƒê·∫∂C BI·ªÜT

### H·ªçc sinh ch·ªâ g·ª≠i ƒë·ªÅ, kh√¥ng l√†m g√¨:
"Em th·ª≠ ƒë·ªçc k·ªπ ƒë·ªÅ v√† l√†m th·ª≠ ph·∫ßn n√†o em t·ª± tin tr∆∞·ªõc nh√©! Sau ƒë√≥ g·ª≠i b√†i l√†m l√™n, th·∫ßy/c√¥ s·∫Ω xem v√† h∆∞·ªõng d·∫´n ph·∫ßn em ch∆∞a r√µ. Vi·ªác t·ª± l√†m s·∫Ω gi√∫p em nh·ªõ l√¢u h∆°n nhi·ªÅu ƒë·∫•y! üòä"

### H·ªçc sinh n√≥i "em kh√¥ng bi·∫øt l√†m":
"Kh√¥ng sao! Ch√∫ng ta c√πng ph√¢n t√≠ch t·ª´ng b∆∞·ªõc:
1. Em hi·ªÉu ƒë·ªÅ b√†i ch∆∞a? ƒê·ªÅ y√™u c·∫ßu t√¨m g√¨?
2. D·∫°ng b√†i n√†y em c√≥ g·∫∑p trong SGK kh√¥ng?
3. Em th·ª≠ nh·ªõ l·∫°i xem c√≥ c√¥ng th·ª©c n√†o li√™n quan kh√¥ng?"

### H·ªçc sinh h·ªèi li√™n t·ª•c kh√¥ng t·ª± l√†m:
"Th·∫ßy/c√¥ th·∫•y em c√≥ th·ªÉ t·ª± l√†m ƒë∆∞·ª£c m√†! Th·∫ßy/c√¥ ƒë√£ g·ª£i √Ω r·ªìi, gi·ªù em th·ª≠ l√†m r·ªìi g·ª≠i l√™n nh√©. T·ª± m√¨nh l√†m ƒë∆∞·ª£c s·∫Ω nh·ªõ l√¢u h∆°n r·∫•t nhi·ªÅu ƒë·∫•y!"

### H·ªçc sinh y√™u c·∫ßu gi·∫£i nhanh:
"Th·∫ßy/c√¥ hi·ªÉu em ƒëang v·ªôi, nh∆∞ng ƒë·ªÉ em th·ª±c s·ª± hi·ªÉu v√† l√†m ƒë∆∞·ª£c b√†i t∆∞∆°ng t·ª± sau n√†y, ch√∫ng ta n√™n c√πng ph√¢n t√≠ch k·ªπ h∆°n nh√©! B√†i n√†y kh√¥ng kh√≥ l·∫Øm ƒë√¢u, em l√†m th·ª≠ ƒëi!"

---

## L∆ØU √ù QUAN TR·ªåNG

‚ö†Ô∏è **KH√îNG BAO GI·ªú:**
- Gi·∫£i to√†n b·ªô b√†i ngay t·ª´ ƒë·∫ßu (tr·ª´ khi h·ªçc sinh y√™u c·∫ßu sau nhi·ªÅu l·∫ßn c·ªë g·∫Øng)
- Cho ƒë√°p √°n tr·ª±c ti·∫øp khi h·ªçc sinh ch∆∞a th·ª≠- L√†m b√†i ki·ªÉm tra/b√†i thi thay h·ªçc sinh

‚úÖ **LU√îN LU√îN:**
- Khuy·∫øn kh√≠ch h·ªçc sinh t·ª± suy nghƒ© tr∆∞·ªõc
- ƒê·∫∑t c√¢u h·ªèi d·∫´n d·∫Øt t∆∞ duy
- Khen ng·ª£i m·ªói n·ªó l·ª±c c·ªßa h·ªçc sinh
- Gi·∫£i th√≠ch B·∫¢N CH·∫§T, kh√¥ng ch·ªâ C√îNG TH·ª®C

---

**Ph∆∞∆°ng ch√¢m**: "M·ªôt AI gia s∆∞ gi·ªèi kh√¥ng ph·∫£i l√† ng∆∞·ªùi gi·∫£i b√†i nhanh nh·∫•t, m√† l√† ng∆∞·ªùi gi√∫p h·ªçc sinh T·ª∞ TIN gi·∫£i b√†i m·ªôt m√¨nh!" üéì;"""

CHAT_RESPONSE_BLUEPRINT = """B·∫°n lu√¥n tr·∫£ l·ªùi ·ªü ƒë·ªãnh d·∫°ng JSON v·ªõi 3 kh√≥a ch√≠nh:
{
  "reply": "Tin nh·∫Øn h·ªôi tho·∫°i. Gi·∫£i th√≠ch ki·∫øn th·ª©c n·ªÅn, g·ª£i √Ω t∆∞ duy t·ª´ng b∆∞·ªõc, nh·∫Øc h·ªçc sinh t·ª± ki·ªÉm tra v√† ƒë·∫∑t c√¢u h·ªèi k·∫ø ti·∫øp.",
  "mindmap_insights": [
    {
      "node_id": "slug-khong-dau",
      "parent_node_id": "ung-dung-dao-ham" | "tinh-don-dieu" | "cuc-tri" | "max-min",
      "label": "T√™n node s√∫c t√≠ch",
      "type": "topic" | "subtopic" | "concept",
      "weakness_summary": "M√¥ t·∫£ ng·∫Øn l·ªó h·ªïng ki·∫øn th·ª©c ho·∫∑c k·ªπ nƒÉng h·ªçc sinh ch∆∞a ch·∫Øc",
      "action_steps": ["G·ª£i √Ω 1", "G·ª£i √Ω 2" (t·ªëi ƒëa 3 c√¢u h∆∞·ªõng d·∫´n th·ª±c h√†nh c·ª• th·ªÉ)]
    }
  ],
  "geogebra": {
    "should_draw": true | false,
    "reason": "Gi·∫£i th√≠ch v√¨ sao c·∫ßn ƒë·ªì th·ªã/h√¨nh h·ªçc (chu·ªói r·ªóng n·∫øu kh√¥ng c·∫ßn)",
    "prompt": "M√¥ t·∫£ ng·∫Øn ƒë·ªÉ g·ª≠i cho AI v·∫Ω h√¨nh",
    "commands": ["Danh s√°ch l·ªánh GeoGebra h·ª£p l·ªá. Ch·ªâ c√≥ gi√° tr·ªã khi should_draw = true"]
  }
}

Y√äU C·∫¶U:
1. "reply" ph·∫£i tham chi·∫øu l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán, b·ªï sung l√Ω thuy·∫øt c·∫ßn thi·∫øt ƒë·ªÉ h·ªçc sinh t·ª± gi·∫£i, k√®m 1-2 c√¢u h·ªèi g·ª£i m·ªü.
2. "mindmap_insights" ph·∫£n √°nh ƒëi·ªÉm y·∫øu r√∫t ra t·ª´ c·∫£ l·ªãch s·ª≠ v√† c√¢u tr·∫£ l·ªùi m·ªõi nh·∫•t. N·∫øu kh√¥ng c√≥ ƒëi·ªÉm m·ªõi th√¨ tr·∫£ v·ªÅ m·∫£ng r·ªóng.
   - Ch·ªâ d√πng c√°c parent_node_id ƒë√£ c√≥ trong mindmap l·ªõp 12: "ung-dung-dao-ham" (g·ªëc), "tinh-don-dieu", "cuc-tri", "max-min".
   - node_id ph·∫£i d·∫°ng slug, duy nh·∫•t.
3. "geogebra":
   - N·∫øu c√¢u h·ªèi li√™n quan ƒë·ªì th·ªã h√†m s·ªë ho·∫∑c h√¨nh h·ªçc kh√¥ng gian/ph·∫≥ng c·∫ßn h√¨nh minh h·ªça th√¨ should_draw = true, cung c·∫•p prompt ng·∫Øn + √≠t nh·∫•t 3 commands.
   - N·∫øu kh√¥ng c·∫ßn h√¨nh, ƒë·∫∑t should_draw = false, reason = "", commands = [].
4. Lu√¥n tr·∫£ v·ªÅ JSON h·ª£p l·ªá (kh√¥ng markdown, kh√¥ng gi·∫£i th√≠ch ngo√†i).
"""

GEOGEBRA_SYSTEM_INSTRUCTION = """B·∫°n l√† m·ªôt chuy√™n gia GeoGebra, chuy√™n chuy·ªÉn ƒë·ªïi m√¥ t·∫£ b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n th√†nh c√°c l·ªánh GeoGebra h·ª£p l·ªá.

üéØ NHI·ªÜM V·ª§:
- Ph√¢n t√≠ch y√™u c·∫ßu v·∫Ω h√¨nh c·ªßa ng∆∞·ªùi d√πng
- Sinh ra dan s√°ch c√°c l·ªánh GeoGebra ch√≠nh x√°c, c√≥ th·ª© t·ª± logic
- ƒê·∫£m b·∫£o c√°c l·ªánh t∆∞∆°ng th√≠ch v·ªõi GeoGebra Classic

üìê C√ö PH√ÅP GEOGEBRA C∆† B·∫¢N:
1. **ƒêi·ªÉm**: A = (2, 3) ho·∫∑c Point({2, 3})
2. **ƒê∆∞·ªùng th·∫≥ng**: y = 2x + 1 ho·∫∑c Line(A, B)
3. **ƒê∆∞·ªùng tr√≤n**: Circle((0,0), 3) ho·∫∑c Circle(A, r)
4. **H√†m s·ªë**: f(x) = x^2 - 4x + 3
5. **Parabol**: y = a*x^2 + b*x + c
6. **Vector**: v = Vector(A, B)
7. **ƒêa gi√°c**: Polygon(A, B, C)
8. **G√≥c**: Angle(A, B, C)
9. **Text**: Text("Label", A)

üîß QUY T·∫ÆC QUAN TR·ªåNG:
- ƒê·ªãnh nghƒ©a c√°c ƒë·ªëi t∆∞·ª£ng c∆° b·∫£n tr∆∞·ªõc (ƒëi·ªÉm, h·ªá s·ªë)
- S·ª≠ d·ª•ng t√™n bi·∫øn ng·∫Øn g·ªçn (A, B, C cho ƒëi·ªÉm)
- Tr√°nh xung ƒë·ªôt t√™n bi·∫øn
- C√°c l·ªánh ph·∫£i ƒë·ªôc l·∫≠p, kh√¥ng ph·ª• thu·ªôc bi·∫øn ngo√†i

‚ö†Ô∏è L∆ØU √ù:
- KH√îNG th√™m gi·∫£i th√≠ch, ch·ªâ tr·∫£ v·ªÅ l·ªánh
- KH√îNG s·ª≠ d·ª•ng k√Ω t·ª± ƒë·∫∑c bi·ªát Vi·ªát Nam trong t√™n bi·∫øn
- ƒê·∫£m b·∫£o c√∫ ph√°p 100% ch√≠nh x√°c

üéØ OUTPUT FORMAT: {"commands": ["command1", "command2", ...]}"""

EXERCISE_SYSTEM_INSTRUCTION = """B·∫°n l√† m·ªôt chuy√™n gia bi√™n so·∫°n b√†i t·∫≠p to√°n THPT l·ªõp 12 Vi·ªát Nam."""

TEST_SYSTEM_INSTRUCTION = """B·∫°n l√† chuy√™n gia bi√™n so·∫°n ƒë·ªÅ thi THPT Qu·ªëc gia m√¥n To√°n.

üéØ QUY T·∫ÆC B·∫ÆT BU·ªòC:

1. **Tr·∫Øc nghi·ªám**: M·ªói c√¢u PH·∫¢I c√≥ ƒë·∫ßy ƒë·ªß d·ªØ li·ªáu
   ‚úÖ ƒê√öNG: "T√¨m ƒë·∫°o h√†m c·ªßa h√†m s·ªë $y = x^3 - 3x^2 + 2$"
   ‚ùå SAI: "T√¨m ƒë·∫°o h√†m c·ªßa h√†m s·ªë" (thi·∫øu h√†m s·ªë c·ª• th·ªÉ)

2. **ƒê√∫ng/Sai**: C√°c m·ªánh ƒë·ªÅ ph·∫£i C·ª§ TH·ªÇ, c√≥ th·ªÉ ƒë√°nh gi√° ƒë∆∞·ª£c
   ‚úÖ ƒê√öNG: "H√†m s·ªë ƒë·ªìng bi·∫øn tr√™n $(1; +\\infty)$"
   ‚ùå SAI: "H√†m s·ªë ƒë·ªìng bi·∫øn" (thi·∫øu kho·∫£ng)

3. **Tr·∫£ l·ªùi ng·∫Øn**: ƒê·ªÅ b√†i r√µ r√†ng, y√™u c·∫ßu t√≠nh to√°n c·ª• th·ªÉ
   ‚úÖ ƒê√öNG: "T√≠nh $\\int_0^2 x^2 dx$"
   ‚ùå SAI: "T√≠nh t√≠ch ph√¢n" (thi·∫øu h√†m s·ªë v√† c·∫≠n)

4. **LaTeX**: D√πng ƒë√∫ng c√∫ ph√°p
   - Inline: $x^2 + 1$
   - Display: $$\\int_a^b f(x)dx$$
   - Ph√¢n s·ªë: $\\frac{a}{b}$
   - V√¥ c·ª±c: $\\infty$

5. **Format JSON**: Kh√¥ng th√™m markdown ```json, ch·ªâ tr·∫£ v·ªÅ object thu·∫ßn t√∫y"""

SUMMARIZE_SYSTEM_INSTRUCTION = """B·∫°n l√† m·ªôt gi·∫£ng vi√™n to√°n h·ªçc chuy√™n t√≥m t·∫Øt ki·∫øn th·ª©c m·ªôt c√°ch s√∫c t√≠ch."""

# ===== FASTAPI APP =====

app = FastAPI(title="Math Tutor API")
app.include_router(node_progress_router)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
def extract_reply_only(raw_text: str) -> str:
    """
    L·∫•y ph·∫ßn n·ªôi dung trong key "reply": " ... " t·ª´ output c·ªßa model,
    k·ªÉ c·∫£ khi to√†n b·ªô kh√¥ng ph·∫£i JSON h·ª£p l·ªá.
    N·∫øu kh√¥ng t√¨m th·∫•y, tr·∫£ l·∫°i nguy√™n chu·ªói.
    """
    if not raw_text:
        return ""

    # B·ªè d·∫•u xu·ªëng d√≤ng d∆∞ th·ª´a ƒë·ªÉ regex d·ªÖ l√†m vi·ªác
    text = raw_text.strip()

    # C·ªë g·∫Øng t√¨m "reply": "...."
    match = re.search(r'"reply"\s*:\s*"([^"]*)"', text, re.DOTALL)
    if match:
        return match.group(1).strip()

    # N·∫øu model d√πng 'reply': '...' (d√πng nh√°y ƒë∆°n) th√¨ b·∫Øt th√™m
    match2 = re.search(r"'reply'\s*:\s*'([^']*)'", text, re.DOTALL)
    if match2:
        return match2.group(1).strip()

    # Kh√¥ng t√¨m ƒë∆∞·ª£c th√¨ tr·∫£ nguy√™n
    return text


# ===== SCHEMAS =====

class MediaPart(BaseModel):
    url: str

class ConversationTurn(BaseModel):
    role: Literal["user", "assistant"]
    content: str


class MindmapInsight(BaseModel):
    node_id: str
    parent_node_id: Optional[str] = None
    label: str
    type: Literal["topic", "subtopic", "concept"] = "concept"
    weakness_summary: Optional[str] = None
    action_steps: Optional[List[str]] = None


class GeogebraInstruction(BaseModel):
    should_draw: bool = False
    reason: Optional[str] = None
    prompt: Optional[str] = None
    commands: Optional[List[str]] = None


class ChatInputSchema(BaseModel):
    userId: Optional[str] = None
    message: str
    history: List[ConversationTurn] = Field(default_factory=list)
    media: Optional[List[MediaPart]] = None

class ProcessDocumentInput(BaseModel):
    userId: str
    documentId: str
    purpose: str = "chat"

class GenerateExercisesInput(BaseModel):
    userId: Optional[str] = None
    topic: str
    difficulty: str = "medium"
    count: int = 3


class SummarizeTopicInput(BaseModel):
    topic: str
    detail_level: str = "medium"

class GeogebraInputSchema(BaseModel):
    request: str
    graph_type: str = "function"

class AnalyzeTestResultInput(BaseModel):
    userId: str
    testAttempt: dict  # TestAttempt object
    weakTopics: List[dict]  # WeakTopic[]

class AnalyzeTestResultOutput(BaseModel):
    analysis: str
    strengths: List[str]
    weaknesses: List[str]
    recommendations: List[str]
    suggestedTopics: List[str]

class GenerateAdaptiveTestInput(BaseModel):
    userId: str
    weakTopics: List[str]
    difficulty: str = "medium"
    
class GenerateTestInput(BaseModel):
    userId: Optional[str] = None
    topic: str
    difficulty: str = "medium"
    testType: str = "standard"  # Th√™m tr∆∞·ªùng n√†y (node, standard, thptqg)
    numQuestions: int = 5       # Th√™m tr∆∞·ªùng n√†y
# ===== HELPER FUNCTIONS =====

def evaluate_node_status(score: float, has_opened: bool) -> str:
    """
    X√°c ƒë·ªãnh tr·∫°ng th√°i node:
    - not_started: ch∆∞a h·ªçc ho·∫∑c ch∆∞a m·ªü node
    - learning: m·ªü r·ªìi nh∆∞ng ƒëi·ªÉm d∆∞·ªõi 80%
    - mastered: ƒëi·ªÉm >= 80% (>= 24/30)
    """
    if not has_opened:
        return "not_started"

    if score >= 24:  # 80% c·ªßa 30 ƒëi·ªÉm
        return "mastered"

    return "learning"

# --- S·ª¨A L·ªñI: H√ÄM D·ªåN D·∫∏P JSON ---
def clean_json_response(raw_text: str) -> str:
    """
    T√¨m kh·ªëi JSON ƒë·∫ßu ti√™n trong chu·ªói, lo·∫°i b·ªè ```json v√† c√°c k√Ω t·ª± kh√¥ng h·ª£p l·ªá.
    """
    if not raw_text:
        return ""

    # T√¨m JSON trong chu·ªói AI tr·∫£ v·ªÅ
    json_match = re.search(r"{[\s\S]*}", raw_text)
    if not json_match:
        print("‚ùå Kh√¥ng t√¨m th·∫•y JSON trong output AI")
        print("Raw response:", raw_text[:400])
        return "" # Tr·∫£ v·ªÅ chu·ªói r·ªóng n·∫øu kh√¥ng t√¨m th·∫•y

    json_text = json_match.group(0).strip()

    # Lo·∫°i k√Ω t·ª± ƒëi·ªÅu khi·ªÉn (nguy√™n nh√¢n ch√≠nh g√¢y JSONDecodeError)
    json_text = re.sub(r"[\x00-\x1F\x7F]", " ", json_text)
    # Lo·∫°i emoji v√† k√Ω t·ª± m·ªü r·ªông Unicode
    json_text = re.sub(r"[\U00010000-\U0010ffff]", "", json_text)
    # Chu·∫©n ho√° d·∫•u ngo·∫∑c k√©p Unicode v·ªÅ ASCII
    json_text = json_text.replace("‚Äú", "\"").replace("‚Äù", "\"")
    json_text = json_text.replace("‚Äò", "'").replace("‚Äô", "'")
    # Lo·∫°i b·ªè xu·ªëng d√≤ng th·∫≠t v√† tab th·∫≠t
    json_text = json_text.replace("\n", " ").replace("\t", " ")
    # Lo·∫°i escape th·ª´a d·∫°ng "\\n", "\\t"
    json_text = json_text.replace("\\n", " ").replace("\\t", " ")

    # X·ª≠ l√Ω n·∫øu AI tr·∫£ v·ªÅ d·∫°ng ```json ... ``` ho·∫∑c ```...```
    if json_text.startswith("```json"):
        json_text = json_text[7:]
    elif json_text.startswith("```"):
        json_text = json_text[3:]
    if json_text.endswith("```"):
        json_text = json_text[:-3]

    return json_text.strip()
# --- K·∫æT TH√öC H√ÄM D·ªåN D·∫∏P JSON ---


# ===== ENDPOINTS =====

@app.get("/")
async def root():
    return {
        "status": "ok", 
        "message": "Math Tutor API with PDF & Word Support",
        "model": "gemini-2.5-flash",
        "supported_formats": ["PDF (.pdf)", "Word (.docx, .doc)"],
        "endpoints": [
            "/api/chat",
            "/api/generate-exercises", 
            "/api/generate-test",
            "/api/process-document",
            "/api/summarize-topic",
            "/api/geogebra",
            "/api/analyze-test-result",
            "/api/generate-adaptive-test"
        ],
        "reference_folders": {
            "exercises": str(EXERCISES_FOLDER),
            "tests": str(TESTS_FOLDER)
        }
    }

# ===== OPTIMIZATION: CACHED MODELS =====
# We can initialize models globally if config is static, but here config varies slightly.
# However, we can keep the client initialization lightweight.
# The `genai.configure` is already done globally.

# --- S·ª¨A L·ªñI 1: T·ªêI ∆ØU H√ìA T·ªêC ƒê·ªò CHAT ---
@app.post("/api/chat")
async def handle_chat(request: ChatInputSchema):
    """Handle chat using a persistent ChatSession for speed."""
    try:
        generation_config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,
            "response_mime_type": "application/json",
        }

        # 1) X√¢y d·ª±ng l·∫°i l·ªãch s·ª≠ cho Gemini ChatSession
        gemini_history = []
        gemini_history = []
        for turn in request.history:
            if not turn.content:
                continue
            mapped_role = "user" if turn.role == "user" else "model"
            gemini_history.append(
                {
                    "role": mapped_role,
                    "parts": [{"text": turn.content}],
                }
            )

        # 2) Kh·ªüi t·∫°o ChatSession v·ªõi l·ªãch s·ª≠ ƒë√£ c√≥
        #    ƒêi·ªÅu n√†y cho ph√©p model duy tr√¨ ng·ªØ c·∫£nh m√† kh√¥ng c·∫ßn g·ª≠i l·∫°i to√†n b·ªô
        #    OPTIMIZATION: Initialize model here or use cached one
        model = genai.GenerativeModel(
            "gemini-2.5-flash",
            generation_config=generation_config,
            system_instruction=CHAT_SYSTEM_INSTRUCTION,
        )
        chat = model.start_chat(history=gemini_history)

        # 3) Chu·∫©n b·ªã n·ªôi dung tin nh·∫Øn M·ªöI
        # RAG INTEGRATION
        context_text = ""
        if request.userId:
            print(f"üîç Searching documents for user {request.userId}...")
            docs = await rag_service.search_similar_documents(request.message, request.userId, purpose="chat")
            if docs:
                context_text = "\n\n=== TH√îNG TIN THAM KH·∫¢O T·ª™ T√ÄI LI·ªÜU C·ª¶A B·∫†N ===\n"
                for d in docs:
                    context_text += f"- [{d['file_name']}]: {d['content']}\n"
                context_text += "==============================================\n"
                print(f"‚úÖ Found {len(docs)} relevant chunks")

        user_prompt = f"""{CHAT_RESPONSE_BLUEPRINT}\n\n{context_text}\nH·ªçc sinh v·ª´a h·ªèi: {request.message}"""
        user_parts = [{"text": user_prompt}]

        if request.media:
            for media in request.media:
                user_parts.append({"media": {"url": media.url}})

        # 4) G·ª≠i tin nh·∫Øn m·ªõi (async)
        #    Model s·∫Ω t·ª± ƒë·ªông n·ªëi l·ªãch s·ª≠ ƒë√£ c√≥ v·ªõi tin nh·∫Øn m·ªõi n√†y
        response = await chat.send_message_async(user_parts)

        # L·∫•y raw text t·ª´ model
        raw_text = response.text if hasattr(response, "text") else None
        if not raw_text:
            raise ValueError("Model kh√¥ng tr·∫£ v·ªÅ ph·∫£n h·ªìi")

        # M·∫∑c ƒë·ªãnh: kh√¥ng mindmap, kh√¥ng v·∫Ω geogebra
        mindmap_data = []
        normalized_geogebra = {
            "should_draw": False,
            "reason": "",
            "prompt": request.message,
            "commands": [],
        }

        # ===================== TRY PARSE JSON =====================
        try:
            # S·ª¨A L·ªñI: S·ª≠ d·ª•ng h√†m d·ªçn d·∫πp JSON
            json_candidate = clean_json_response(raw_text)
            
            if not json_candidate:
                raise ValueError("Kh√¥ng t√¨m th·∫•y JSON h·ª£p l·ªá trong ph·∫£n h·ªìi")

            payload = json.loads(json_candidate)

            # N·∫øu parse ƒë∆∞·ª£c JSON, ∆∞u ti√™n l·∫•y reply trong JSON
            reply_text = (
                payload.get("reply")
                or payload.get("message")
                or extract_reply_only(raw_text)
            )

            # mindmap_insights n·∫øu l√† list th√¨ d√πng, kh√¥ng th√¨ b·ªè qua
            md = payload.get("mindmap_insights")
            if isinstance(md, list):
                mindmap_data = md

            # geogebra n·∫øu c√≥ c·∫•u tr√∫c ƒë√∫ng th√¨ d√πng cho lu·ªìng GeoGebra
            geogebra_block = payload.get("geogebra") or {}
            normalized_geogebra = {
                "should_draw": bool(geogebra_block.get("should_draw")),
                "reason": geogebra_block.get("reason") or "",
                "prompt": geogebra_block.get("prompt") or request.message,
                "commands": geogebra_block.get("commands")
                if isinstance(geogebra_block.get("commands"), list)
                else [],
            }

        except Exception as e:
            # JSON h·ªèng -> ch·ªâ l·∫•y ph·∫ßn reply, b·ªè mindmap & geogebra
            print(f"JSON parse failed, fallback to reply-only: {e}")
            reply_text = extract_reply_only(raw_text)

        # Tr·∫£ response v·ªÅ frontend: chat ch·ªâ d√πng field "reply"
        return {
            "reply": reply_text,
            "mindmap_insights": mindmap_data,
            "geogebra": normalized_geogebra,
        }

    except Exception as e:
        print(f"Chat error: {e}")
        raise HTTPException(status_code=500, detail=str(e))
# --- K·∫æT TH√öC S·ª¨A L·ªñI CHAT ---


class UpdateNodeScorePayload(BaseModel):
    user_id: int
    node_id: int
    score: int

@app.post("/node-progress/updateScore")
def update_node_score(payload: UpdateNodeScorePayload):
    # Gi·∫£ s·ª≠ b·∫°n d√πng Supabase client:
    from supabase import create_client
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

    res = supabase.table("user_nodes") \
        .update({"score": payload.score}) \
        .eq("user_id", payload.user_id) \
        .eq("node_id", payload.node_id) \
        .execute()
    return res.data

@app.post("/node-progress/openNode")
def open_node(user_id: int, node_id: int):
    from supabase import create_client
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

    res = supabase.table("user_nodes") \
        .update({"score": 0}) \
        .eq("user_id", user_id) \
        .eq("node_id", node_id) \
        .execute()
    return res.data


@app.post("/api/generate-exercises")
async def handle_generate_exercises(request: GenerateExercisesInput):
    """Generate math exercises based on topic"""
    try:
        print(f"üìö Generating exercises for topic: {request.topic}")
        
        # RAG Integration
        context_text = ""
        if request.userId:
             docs = await rag_service.search_similar_documents(request.topic, request.userId, purpose="test") # Use test materials
             if docs:
                context_text = "\n\n=== T√ÄI LI·ªÜU THAM KH·∫¢O ===\n"
                for d in docs:
                    context_text += f"- {d['content']}\n"
        
        # Fallback to local files if no RAG results (optional, or keep both)
        reference_text = load_reference_materials(str(EXERCISES_FOLDER), max_files=3)
        
        generation_config = {
            "temperature": 0.7,
        }
        
        # OPTIMIZATION: Re-use model if possible, but for now just keep it local as it's stateless
        model = genai.GenerativeModel(
            'gemini-2.5-flash',
            generation_config=generation_config,
            system_instruction=EXERCISE_SYSTEM_INSTRUCTION
        )
        
        prompt = f"""T·∫°o {request.count} b√†i t·∫≠p to√°n h·ªçc v·ªÅ ch·ªß ƒë·ªÅ: "{request.topic}"
ƒê·ªô kh√≥: {request.difficulty}

T√†i li·ªáu tham kh·∫£o:
{context_text}
{reference_text}

Y√äU C·∫¶U:
ƒê·ªô kh√≥: {request.difficulty}

Y√äU C·∫¶U:
- B√†i t·∫≠p ph·∫£i ph√π h·ª£p v·ªõi ch∆∞∆°ng tr√¨nh To√°n 12 Vi·ªát Nam
- Cung c·∫•p l·ªùi gi·∫£i chi ti·∫øt t·ª´ng b∆∞·ªõc
- S·ª≠ d·ª•ng c√¥ng th·ª©c LaTeX khi c·∫ßn
- Format Markdown (kh√¥ng c·∫ßn JSON)

ƒê·ªãnh d·∫°ng mong mu·ªën:
## B√†i 1
**ƒê·ªÅ b√†i:** [N·ªôi dung ƒë·ªÅ]

**L·ªùi gi·∫£i:**
[Gi·∫£i th√≠ch chi ti·∫øt]

**ƒê√°p √°n:** [K·∫øt qu·∫£ cu·ªëi c√πng]

---

## B√†i 2
[Ti·∫øp t·ª•c...]"""
        
        response = model.generate_content(prompt)
        
        if not response or not hasattr(response, 'text'):
            raise ValueError("Model kh√¥ng tr·∫£ v·ªÅ ph·∫£n h·ªìi")
        
        exercises_text = response.text.strip()
        
        if not exercises_text:
            raise ValueError("Model tr·∫£ v·ªÅ n·ªôi dung tr·ªëng")
        
        print(f"‚úÖ Generated exercises: {len(exercises_text)} characters")
        
        return {
            "exercises": exercises_text
        }
        
    except Exception as e:
        print(f"‚ùå Generate exercises error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"L·ªói: {str(e)}")

@app.post("/api/process-document")
async def process_document(request: ProcessDocumentInput):
    """Trigger document processing (RAG)"""
    try:
        success = await rag_service.process_document(
            user_id=request.userId,
            document_id=request.documentId,
            purpose=request.purpose
        )
        if not success:
            raise HTTPException(status_code=500, detail="Processing failed")
        return {"status": "ok", "message": "Document processed successfully"}
    except Exception as e:
        print(f"Process document error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==============================
#  API T·∫†O TEST D·ª∞A TR√äN NODE
# ==============================

class NodeTestRequest(BaseModel):
    topic: str   # ch√≠nh l√† node.label


# ============================
#   NODE TEST GENERATOR API
# ============================

from pydantic import BaseModel
from fastapi import HTTPException
import json
import google.generativeai as genai


class NodeTestRequest(BaseModel):
    userId: Optional[str] = None
    topic: str


@app.post("/api/generate-node-test")
async def generate_node_test(req: NodeTestRequest):
    """Generate test based on current node content"""
    try:
        topic = req.topic

        model = genai.GenerativeModel(
            "gemini-2.5-flash",
            generation_config={
                "temperature": 0.6,
                "response_mime_type": "application/json",
            },
            system_instruction="B·∫°n l√† h·ªá th·ªëng sinh ƒë·ªÅ ki·ªÉm tra to√°n chu·∫©n THPT."
        )

        # ========================
        #      PROMPT CHU·∫®N (S·ª¨A L·ªñI 2A: B·∫ÆT BU·ªòC D√ôNG LATEX)
        # ========================
        # RAG Integration
        context_text = ""
        if req.userId:
            docs = await rag_service.search_similar_documents(topic, req.userId, purpose="test")
            if docs:
                context_text = "\n\n=== T√ÄI LI·ªÜU THAM KH·∫¢O ===\n"
                for d in docs:
                    context_text += f"- {d['content']}\n"

        prompt = f"""
T·∫°o ƒë·ªÅ ki·ªÉm tra to√°n l·ªõp 12 d·ª±a 100% tr√™n ch·ªß ƒë·ªÅ: "{topic}"

T√ÄI LI·ªÜU THAM KH·∫¢O:
{context_text}

Y√äU C·∫¶U QUAN TR·ªåNG V·ªÄ N·ªòI DUNG:
- S·ª≠ d·ª•ng LaTeX cho c√¥ng th·ª©c: $x^2$ ho·∫∑c $x^2 + 2x + 1 = 0$
- M·ªói c√¢u h·ªèi PH·∫¢I c√≥ ƒë·∫ßy ƒë·ªß d·ªØ li·ªáu (ph∆∞∆°ng tr√¨nh, h√†m s·ªë, ƒë·ªì th·ªã...)
- C√¢u h·ªèi ph·∫£i C·ª§ TH·ªÇ, KH√îNG m∆° h·ªì
- ƒê√°p √°n ph·∫£i CH√çNH X√ÅC

***QUAN TR·ªåNG V·ªÄ JSON (B·∫ÆT BU·ªòC):***
To√†n b·ªô ƒë·∫ßu ra l√† m·ªôt chu·ªói JSON. Do ƒë√≥, t·∫•t c·∫£ c√°c k√Ω t·ª± g·∫°ch ch√©o ng∆∞·ª£c (\\) B√äN TRONG chu·ªói (v√≠ d·ª•: trong LaTeX) PH·∫¢I ƒë∆∞·ª£c tho√°t (escaped) b·∫±ng c√°ch nh√¢n ƒë√¥i.
V√ç D·ª§:
- SAI: "$\\frac{{1}}{{2}}$"
- ƒê√öNG: "$\\\\frac{{1}}{{2}}$"
- SAI: "$\\lim_{{x \\to 0}}$"
- ƒê√öNG: "$\\\\lim_{{x \\\\to 0}}$"
- SAI: "$(1; +\\infty)$"
- ƒê√öNG: "$(1; +\\\\infty)$"

Y√äU C·∫¶U S·ªê L∆Ø·ª¢NG C√ÇU H·ªéI:
- 15 c√¢u multiple-choice (Tr·∫Øc nghi·ªám 4 l·ª±a ch·ªçn)
- 4 c√¢u true-false (Tr·∫Øc nghi·ªám ƒë√∫ng sai, m·ªói c√¢u 4 √Ω)
- 2 c√¢u short-answer (Tr·∫Øc nghi·ªám tr·∫£ l·ªùi ng·∫Øn)

C·∫§U TR√öC ƒê·ªÄ THI CHU·∫®N THPT 2025:
1. Ph·∫ßn 1: Tr·∫Øc nghi·ªám nhi·ªÅu l·ª±a ch·ªçn (4 ph∆∞∆°ng √°n, ch·ªçn 1 ƒë√∫ng).
2. Ph·∫ßn 2: Tr·∫Øc nghi·ªám ƒë√∫ng sai (M·ªói c√¢u h·ªèi c√≥ 4 √Ω a,b,c,d. H·ªçc sinh x√©t t√≠nh ƒë√∫ng sai c·ªßa t·ª´ng √Ω).
3. Ph·∫ßn 3: Tr·∫Øc nghi·ªám tr·∫£ l·ªùi ng·∫Øn (H·ªçc sinh ƒëi·ªÅn ƒë√°p √°n s·ªë).

C·∫§U TR√öC JSON B·∫ÆT BU·ªòC (TUY·ªÜT ƒê·ªêI PH·∫¢I ƒê√öNG):
{{
  "title": "KI·ªÇM TRA {topic.upper()}",
  "description": "B√†i ki·ªÉm tra d√†nh ri√™ng cho ch·ªß ƒë·ªÅ {topic}",
  "parts": {{
    "multipleChoice": {{
      "title": "PH·∫¶N 1: TR·∫ÆC NGHI·ªÜM",
      "questions": [
        {{
          "id": 1,
          "type": "multiple-choice",
          "prompt": "C√¢u h·ªèi...",
          "options": ["A", "B", "C", "D"],
          "answer": 0
        }}
      ]
    }},
    "trueFalse": {{
      "title": "PH·∫¶N 2: ƒê√öNG/SAI",
      "questions": [
        {{
          "id": "tf1",
          "type": "true-false",
          "prompt": "C√¢u h·ªèi...",
          "statements": ["...", "...", "...", "..."],
          "answer": [true, false, true, false]
        }}
      ]
    }},
    "shortAnswer": {{
      "title": "PH·∫¶N 3: TR·∫¢ L·ªúI NG·∫ÆN",
      "questions": [
        {{
          "id": "sa1",
          "type": "short-answer",
          "prompt": "C√¢u h·ªèi...",
          "answer": "k·∫øt qu·∫£"
        }}
      ]
    }}
  }}
}}

CH·ªà TR·∫¢ V·ªÄ JSON THU·∫¶N.
KH√îNG markdown.
KH√îNG code block.
T·∫§T C·∫¢ D·∫§U \\ TRONG LATEX PH·∫¢I ƒê∆Ø·ª¢C ESCAPE (v√≠ d·ª•: \\\\frac, \\\\lim, \\\\infty).
"""


        # ========================
        #        G·ªåI AI
        # ========================
        response = model.generate_content(prompt)
        raw = response.text

        # ========================
        # VALIDATE JSON (S·ª¨A L·ªñI 2B: D√ôNG H√ÄM CLEAN_JSON)
        # ========================
        try:
            json_text = clean_json_response(raw)
            if not json_text:
                raise ValueError("Kh√¥ng t√¨m th·∫•y JSON h·ª£p l·ªá")
            
            data = json.loads(json_text)
        except Exception as e:
            print(f"‚ùå RAW JSON ERROR: {e}")
            print(f"Raw response: {raw[:300]}...")
            raise HTTPException(
                status_code=500, 
                detail="AI tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá."
            )
        
        if "parts" not in data:
            print(f"‚ùå Thi·∫øu 'parts' trong JSON: {data}")
            raise HTTPException(status_code=500, detail="Thi·∫øu 'parts' trong JSON")

        return {
            "topic": topic,
            "test": data
        }

    except Exception as e:
        print(f"‚ùå NODE TEST ERROR: {e}")
        raise HTTPException(status_code=500, detail=str(e))



# --- Ch·ªâ function utility ---
def escape_backslashes(obj):
    if isinstance(obj, dict):
        return {k: escape_backslashes(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [escape_backslashes(x) for x in obj]
    elif isinstance(obj, str):
        return obj.replace("\\", "\\\\")
    else:
        return obj

@app.post("/api/generate-test")
async def handle_generate_test(request: GenerateTestInput):
    """Generate a test based on PDF/Word reference materials"""
    try:
        print(f"üìù Loading test reference materials for topic: {request.topic}")
        reference_text = load_reference_materials(str(TESTS_FOLDER), max_files=3)

        generation_config = {
            "temperature": 0.6,
            "response_mime_type": "application/json",
        }

        model = genai.GenerativeModel(
            'gemini-2.5-flash',
            generation_config=generation_config,
            system_instruction=TEST_SYSTEM_INSTRUCTION
        )

        # RAG Integration
        context_text = ""
        if request.userId:
            docs = await rag_service.search_similar_documents(request.topic, request.userId, purpose="test")
            if docs:
                context_text = "\n\n=== T√ÄI LI·ªÜU THAM KH·∫¢O T·ª™ RAG ===\n"
                for d in docs:
                    context_text += f"- {d['content']}\n"

        # --- PROMPT GI·ªÆ NGUY√äN --- 
        prompt = f"""T·∫°o ƒë·ªÅ ki·ªÉm tra TO√ÅN L·ªöP 12 v·ªÅ ch·ªß ƒë·ªÅ: "{request.topic}" ƒê·ªô kh√≥: {request.difficulty} T√ÄI LI·ªÜU THAM KH·∫¢O: {context_text} {reference_text if reference_text else "Kh√¥ng c√≥ t√†i li·ªáu. T·∫°o ƒë·ªÅ theo chu·∫©n THPT QG."} QUY T·∫ÆC QUAN TR·ªåNG (CHU·∫®N FORM THPT 2025): 1. M·ªói c√¢u h·ªèi PH·∫¢I c√≥ ƒë·∫ßy ƒë·ªß d·ªØ li·ªáu (ph∆∞∆°ng tr√¨nh, h√†m s·ªë, ƒë·ªì th·ªã...) 2. S·ª≠ d·ª•ng LaTeX cho c√¥ng th·ª©c: $x^2$ ho·∫∑c $x^2 + 2x + 1 = 0$ 3. C√¢u h·ªèi ph·∫£i C·ª§ TH·ªÇ, KH√îNG m∆° h·ªì 4. ƒê√°p √°n ph·∫£i CH√çNH X√ÅC 5. C·∫•u tr√∫c ƒë·ªÅ: - Ph·∫ßn 1: Tr·∫Øc nghi·ªám 4 l·ª±a ch·ªçn (A,B,C,D) - Ph·∫ßn 2: Tr·∫Øc nghi·ªám ƒê√∫ng/Sai (4 √Ω a,b,c,d) - Ph·∫ßn 3: Tr·∫£ l·ªùi ng·∫Øn (ƒêi·ªÅn s·ªë) V√ç D·ª§ M·∫™U: TR·∫ÆC NGHI·ªÜM T·ªêT: "C√¢u 1: Ph∆∞∆°ng tr√¨nh $x^2 - 5x + 6 = 0$ c√≥ bao nhi√™u nghi·ªám?" TR·∫ÆC NGHI·ªÜM SAI (THI·∫æU D·ªÆ LI·ªÜU): "C√¢u 1: Ph∆∞∆°ng tr√¨nh c√≥ bao nhi√™u nghi·ªám?" ‚ùå ƒê√öNG/SAI T·ªêT: "C√¢u 5: Cho h√†m s·ªë $y = x^3 - 3x + 1$. X√©t t√≠nh ƒë√∫ng/sai c·ªßa c√°c m·ªánh ƒë·ªÅ sau: a) H√†m s·ªë ƒë·ªìng bi·∫øn tr√™n kho·∫£ng $(1; +\\infty)$ b) ƒê·ªì th·ªã h√†m s·ªë c·∫Øt tr·ª•c ho√†nh t·∫°i 3 ƒëi·ªÉm c) H√†m s·ªë c√≥ c·ª±c ƒë·∫°i t·∫°i $x = -1$ d) $\\lim_{{x \\to +\\infty}} y = +\\infty$" QUAN TR·ªåNG - PH·∫¶N ƒê√öNG/SAI: C√¢u h·ªèi ƒë√∫ng/sai PH·∫¢I c√≥ c·∫•u tr√∫c: - prompt: "C√¢u X: Cho [d·ªØ li·ªáu c·ª• th·ªÉ]. X√©t t√≠nh ƒë√∫ng/sai c·ªßa c√°c m·ªánh ƒë·ªÅ sau:" - statements: M·∫£ng 4 m·ªánh ƒë·ªÅ C·ª§ TH·ªÇ, c√≥ th·ªÉ ƒë√°nh gi√° ƒë∆∞·ª£c V√ç D·ª§ M·∫™U ƒê√öNG: {{ "id": "tf1", "type": "true-false", "prompt": "C√¢u 5: Cho h√†m s·ªë $y = x^3 - 3x + 1$. X√©t t√≠nh ƒë√∫ng/sai:", "statements": [ "H√†m s·ªë ƒë·ªìng bi·∫øn tr√™n kho·∫£ng $(1; +\\infty)$", "ƒê·ªì th·ªã h√†m s·ªë c·∫Øt tr·ª•c ho√†nh t·∫°i 3 ƒëi·ªÉm", "H√†m s·ªë c√≥ c·ª±c ƒë·∫°i t·∫°i $x = -1$", "Gi·ªõi h·∫°n $\\lim_{{x \\to +\\infty}} y = +\\infty$" ], "answer": [true, true, true, true] }} V√ç D·ª§ SAI (KH√îNG L√ÄM TH·∫æ N√ÄY): {{ "statements": ["a) ƒê√∫ng", "b) Sai", "c) ƒê√∫ng", "d) Sai"] ‚ùå }} ***QUAN TR·ªåNG V·ªÄ JSON (B·∫ÆT BU·ªòC):*** To√†n b·ªô ƒë·∫ßu ra l√† m·ªôt chu·ªói JSON. Do ƒë√≥, t·∫•t c·∫£ c√°c k√Ω t·ª± g·∫°ch ch√©o ng∆∞·ª£c (\\) B√äN TRONG chu·ªói (v√≠ d·ª•: trong LaTeX) PH·∫¢I ƒë∆∞·ª£c tho√°t (escaped) b·∫±ng c√°ch nh√¢n ƒë√¥i. V√ç D·ª§: - SAI: "$\\frac{{1}}{{2}}$" - ƒê√öNG: "$\\\\frac{{1}}{{2}}$" - SAI: "$\\lim_{{x \\to 0}}$" - ƒê√öNG: "$\\\\lim_{{x \\\\to 0}}$" - SAI: "$(1; +\\infty)$" - ƒê√öNG: "$(1; +\\\\infty)$" Y√äU C·∫¶U: Tr·∫£ v·ªÅ JSON thu·∫ßn t√∫y, KH√îNG markdown code block: Tr·∫£ v·ªÅ JSON: {{ "title": "KI·ªÇM TRA {request.topic.upper()}", "parts": {{ "multipleChoice": {{ ... }}, "trueFalse": {{ "title": "PH·∫¶N 2: ƒê√öNG/SAI", "questions": [ {{ "id": "tf1", "type": "true-false", "prompt": "C√¢u 5: Cho h√†m s·ªë $y = 2x^2 - 4x + 1$. X√©t t√≠nh ƒë√∫ng/sai c·ªßa c√°c m·ªánh ƒë·ªÅ sau:", "statements": [ "ƒê·ªì th·ªã h√†m s·ªë c√≥ tr·ª•c ƒë·ªëi x·ª©ng $x = 1$", "H√†m s·ªë c√≥ gi√° tr·ªã nh·ªè nh·∫•t b·∫±ng $-1$", "ƒê·ªì th·ªã h√†m s·ªë ƒëi qua ƒëi·ªÉm $(0, 1)$", "H√†m s·ªë ngh·ªãch bi·∫øn tr√™n kho·∫£ng $(-\\\\infty; 1)$" ], "answer": [true, true, true, true] }} ] }}, "shortAnswer": {{ ... }} }} }} KH√îNG d√πng a), b), c), d) trong statements! M·ªói statement l√† m·ªôt m·ªánh ƒë·ªÅ ho√†n ch·ªânh! L∆ØU √ù B·∫ÆT BU·ªòC: - KH√îNG d√πng markdown
json ...
- M·ªói c√¢u h·ªèi PH·∫¢I c√≥ ƒë·∫ßy ƒë·ªß d·ªØ li·ªáu c·ª• th·ªÉ - LaTeX d√πng $ cho inline, $ cho display - T·∫§T C·∫¢ D·∫§U \\ TRONG LATEX PH·∫¢I ƒê∆Ø·ª¢C ESCAPE (v√≠ d·ª•: \\\\frac, \\\\lim, \\\\infty) - answer trong multipleChoice: 0=option[0], 1=option[1], 2=option[2], 3=option[3] - answer trong trueFalse: [true, false, true, false] - answer trong shortAnswer: string s·ªë (max 6 k√Ω t·ª±)"""

        response = model.generate_content(prompt)

        # --- Parse JSON an to√†n ---
        try:
            json_text = clean_json_response(response.text)
            if not json_text:
                raise ValueError("Kh√¥ng t√¨m th·∫•y JSON h·ª£p l·ªá")

            json_text = clean_json_response(response.text)
            if not json_text:
                raise ValueError("Kh√¥ng t√¨m th·∫•y JSON h·ª£p l·ªá")

            # ‚ú® S·ª≠a ·ªü ƒë√¢y: escape \ tr∆∞·ªõc khi json.loads
            safe_json_text = json_text.replace("\\", "\\\\")  # t·∫•t c·∫£ \ ‚Üí \\

            result = json.loads(safe_json_text)



        except json.JSONDecodeError as e:
            print(f"‚ùå JSON parse error: {e}")
            print(f"Raw response: {response.text[:500]}")
            raise HTTPException(
                status_code=500,
                detail="AI tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i."
            )

        # Validate structure
        if "parts" not in result or "multipleChoice" not in result["parts"]:
            raise HTTPException(status_code=500, detail="D·ªØ li·ªáu ƒë·ªÅ thi thi·∫øu c·∫•u tr√∫c 'parts' ho·∫∑c 'multipleChoice'")

        return {
            "topic": request.topic,
            "difficulty": request.difficulty,
            "has_reference": bool(reference_text),
            "test": result
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Generate test error: {e}")
        import traceback
        traceback.print_exc()

        error_message = str(e)
        if "429" in error_message or "Resource exhausted" in error_message:
            raise HTTPException(
                status_code=429,
                detail="API Google ƒëang qu√° t·∫£i. Vui l√≤ng ƒë·ª£i 1-2 ph√∫t r·ªìi th·ª≠ l·∫°i."
            )

        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/summarize-topic")
async def handle_summarize_topic(request: SummarizeTopicInput):
    """Summarize a math topic"""
    try:
        print(f"üìñ Summarizing topic: {request.topic}")
        
        generation_config = {
            "temperature": 0.5,
        }
        
        model = genai.GenerativeModel(
            'gemini-2.5-flash',
            generation_config=generation_config,
            system_instruction=SUMMARIZE_SYSTEM_INSTRUCTION
        )
        
        prompt = f"""T√≥m t·∫Øt ch·ªß ƒë·ªÅ sau m·ªôt c√°ch ng·∫Øn g·ªçn, s√∫c t√≠ch v√† d·ªÖ hi·ªÉu. 
S·ª≠ d·ª•ng:
- C√°c g·∫°ch ƒë·∫ßu d√≤ng (bullet points)
- C√¥ng th·ª©c LaTeX khi c·∫ßn thi·∫øt
- Ti√™u ƒë·ªÅ ph·ª• cho t·ª´ng ph·∫ßn

Ch·ªß ƒë·ªÅ: {request.topic}
ƒê·ªô chi ti·∫øt: {request.detail_level}"""
        
        response = model.generate_content(prompt)
        
        if not response or not hasattr(response, 'text'):
            raise ValueError("Model kh√¥ng tr·∫£ v·ªÅ ph·∫£n h·ªìi")
        
        summary_text = response.text.strip()
        
        if not summary_text:
            raise ValueError("Model tr·∫£ v·ªÅ n·ªôi dung tr·ªëng")
        
        print(f"‚úÖ Generated summary: {len(summary_text)} characters")
        
        return {
            "topic": request.topic,
            "summary": summary_text
        }
        
    except Exception as e:
        print(f"‚ùå Summarize topic error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"L·ªói: {str(e)}")


@app.post("/api/geogebra")
async def handle_geogebra(request: GeogebraInputSchema):
    """Generate GeoGebra commands"""
    try:
        generation_config = {
            "temperature": 0.3,
            "response_mime_type": "application/json",
        }
        
        model = genai.GenerativeModel(
            'gemini-2.5-flash',
            generation_config=generation_config,
            system_instruction=GEOGEBRA_SYSTEM_INSTRUCTION
        )
        
        prompt = f"""T·∫°o l·ªánh GeoGebra cho: {request.request}

Tr·∫£ v·ªÅ JSON:
{{
  "commands": ["command1", "command2"]
}}"""
        
        response = model.generate_content(prompt)
        # S·ª¨A L·ªñI: D√πng h√†m clean_json
        json_text = clean_json_response(response.text)
        if not json_text:
            raise ValueError("Kh√¥ng t√¨m th·∫•y JSON h·ª£p l·ªá")
            
        result = json.loads(json_text)
        
        if "commands" not in result or not isinstance(result["commands"], list):
            raise ValueError("Invalid response format")
        
        return result
        
    except Exception as e:
        print(f"Geogebra error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/analyze-test-result")
async def handle_analyze_test_result(request: AnalyzeTestResultInput):
    """
    Ph√¢n t√≠ch k·∫øt qu·∫£ b√†i ki·ªÉm tra v√† ƒë∆∞a ra ƒë√°nh gi√°, l·ªùi khuy√™n chi ti·∫øt
    """
    try:
        generation_config = {
            "temperature": 0.6,
        }
        
        model = genai.GenerativeModel(
            'gemini-2.5-flash',
            generation_config=generation_config,
        )
        
        attempt = request.testAttempt
        weak_topics = request.weakTopics
        
        incorrect_answers_str = ""
        try:
            incorrect_answers = [a for a in attempt['answers'] if not a['isCorrect']]
            
            if not incorrect_answers:
                incorrect_answers_str = "**H·ªçc sinh ƒë√£ tr·∫£ l·ªùi ƒë√∫ng t·∫•t c·∫£ c√°c c√¢u!**\n"
            else:
                incorrect_answers_str = "**DANH S√ÅCH C√ÅC C√ÇU TR·∫¢ L·ªúI SAI (L√†m c∆° s·ªü ch·∫©n ƒëo√°n):**\n"
                for i, ans in enumerate(incorrect_answers[:5]): 
                    incorrect_answers_str += (
                        f"{i+1}. Ch·ªß ƒë·ªÅ: {ans.get('topic', 'N/A')}\n"
                        f"   - Lo·∫°i c√¢u h·ªèi: {ans.get('questionType', 'N/A')}\n"
                        f"   - ƒê√£ ch·ªçn: {ans.get('userAnswer', 'N/A')}\n"
                        f"   - ƒê√°p √°n ƒë√∫ng: {ans.get('correctAnswer', 'N/A')}\n\n"
                    )
        except Exception as e:
            print(f"Warning: Kh√¥ng th·ªÉ tr√≠ch xu·∫•t c√¢u sai: {e}")
            incorrect_answers_str = "Kh√¥ng th·ªÉ t·∫£i chi ti·∫øt c√°c c√¢u sai."
        
        prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia gi√°o d·ª•c v√† gia s∆∞ to√°n h·ªçc AI. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch s√¢u k·∫øt qu·∫£ b√†i l√†m c·ªßa h·ªçc sinh, kh√¥ng ch·ªâ b√°o c√°o ƒëi·ªÉm s·ªë m√† c√≤n **ch·∫©n ƒëo√°n c√°c "l·ªói t∆∞ duy" (thinking gaps)** v√† c√°c "kh√°i ni·ªám hi·ªÉu l·∫ßm" (misconceptions).

**TH√îNG TIN B√ÄI L√ÄM:**
- ƒêi·ªÉm s·ªë: {attempt.get('score', 0):.1f}/100
- S·ªë c√¢u ƒë√∫ng: {attempt.get('correctAnswers', 0)}/{attempt.get('totalQuestions', 0)}
- Th·ªùi gian l√†m b√†i: {attempt.get('timeSpent', 0)} gi√¢y

**TH·ªêNG K√ä CH·ª¶ ƒê·ªÄ Y·∫æU (t·ª´ Client):**
{chr(10).join([f"- {t.get('topic', 'N/A')}: {t.get('accuracy', 0):.1f}% ({t.get('correctAnswers', 0)}/{t.get('totalQuestions', 0)} c√¢u)" for t in weak_topics])}

{incorrect_answers_str}

**Y√äU C·∫¶U PH√ÇN T√çCH (TR·∫¢ V·ªÄ JSON):**

1.  **analysis (Ph√¢n t√≠ch t·ªïng quan)**:
    Nh·∫≠n x√©t chung (2-3 c√¢u) v·ªÅ k·∫øt qu·∫£ b√†i l√†m.

2.  **strengths (ƒêi·ªÉm m·∫°nh)**:
    Nh·ªØng g√¨ h·ªçc sinh l√†m t·ªët (v√≠ d·ª•: "L√†m t·ªët ph·∫ßn ƒê√∫ng/Sai", "N·∫Øm v·ªØng ch·ªß ƒë·ªÅ X").

3.  **weaknesses (Ph√¢n t√≠ch l·ªói sai & L·ªói t∆∞ duy)**:
    * **QUAN TR·ªåNG NH·∫§T**: D·ª±a v√†o "DANH S√ÅCH C√ÅC C√ÇU TR·∫¢ L·ªúI SAI" ·ªü tr√™n, h√£y ch·∫©n ƒëo√°n c√°c l·ªói sai c·ª• th·ªÉ.
    * **KH√îNG** ch·ªâ n√≥i chung chung l√† "y·∫øu ch·ªß ƒë·ªÅ X".
    * **H√ÉY** ch·∫©n ƒëo√°n NGUY√äN NH√ÇN. V√≠ d·ª•:
        - "H·ªçc sinh c√≥ v·∫ª b·ªã nh·∫ßm l·∫´n gi·ªØa c·ª±c tr·ªã v√† ƒëi·ªÉm u·ªën, th·ªÉ hi·ªán ·ªü c√¢u...".
        - "L·ªói t√≠nh to√°n c∆° b·∫£n (sai d·∫•u) khi gi·∫£i ph∆∞∆°ng tr√¨nh ƒë·∫°o h√†m".
        - "Ch∆∞a n·∫Øm v·ªØng c√¥ng th·ª©c t√≠nh th·ªÉ t√≠ch kh·ªëi n√≥n (nh·∫ßm v·ªõi c√¥ng th·ª©c kh·ªëi ch√≥p)".
        - "ƒê·ªçc ƒë·ªÅ kh√¥ng k·ªπ, b·ªè s√≥t ƒëi·ªÅu ki·ªán (v√≠ d·ª•: 's·ªë nguy√™n d∆∞∆°ng')".
        - "Hi·ªÉu sai b·∫£n ch·∫•t c·ªßa ti·ªám c·∫≠n ƒë·ª©ng".

4.  **recommendations (Khuy·∫øn ngh·ªã & Ki·∫øn th·ª©c tr·ªçng t√¢m)**:
    * D·ª±a tr√™n "weaknesses", ƒë∆∞a ra l·ªùi khuy√™n C·ª§ TH·ªÇ, mang t√≠nh H√ÄNH ƒê·ªòNG.
    * Ch·ªâ r√µ c√°c C√îNG TH·ª®C, ƒê·ªäNH NGHƒ®A, ho·∫∑c PH∆Ø∆†NG PH√ÅP gi·∫£i n√†o c·∫ßn ƒë∆∞·ª£c √¥n t·∫≠p.
    * V√≠ d·ª•:
        - "C·∫ßn √¥n l·∫°i b·∫£ng ƒë·∫°o h√†m c·ªßa c√°c h√†m s·ªë c∆° b·∫£n (ƒë·∫∑c bi·ªát l√† h√†m loga, m≈©)".
        - "Xem l·∫°i 3 b∆∞·ªõc ƒë·ªÉ t√¨m ti·ªám c·∫≠n c·ªßa ƒë·ªì th·ªã h√†m s·ªë".
        - "Luy·ªán t·∫≠p 5 b√†i t·∫≠p v·ªÅ nh·∫≠n di·ªán ƒë·ªì th·ªã h√†m s·ªë b·∫≠c 3 v√† b·∫≠c 4 tr√πng ph∆∞∆°ng".

5.  **suggestedTopics (Ch·ªß ƒë·ªÅ n√™n √¥n t·∫≠p)**:
    Li·ªát k√™ 3-5 ch·ªß ƒë·ªÅ ch√≠nh c·∫ßn √¥n (d·ª±a tr√™n `weak_topics` v√† `weaknesses`).

**ƒê·ªäNH D·∫†NG JSON TR·∫¢ V·ªÄ (B·∫ÆT BU·ªòC):**
{{
  "analysis": "...",
  "strengths": ["...", "..."],
  "weaknesses": ["...", "..."],
  "recommendations": ["...", "...", "..."],
  "suggestedTopics": ["...", "...", "..."]
}}

L∆ØU √ù: 
- D√πng gi·ªçng ƒëi·ªáu th√¢n thi·ªán, kh√≠ch l·ªá, nh∆∞ m·ªôt gia s∆∞
- T·∫≠p trung v√†o vi·ªác gi√∫p h·ªçc sinh T·ª∞ TIN h∆°n"""
        
        response = model.generate_content(prompt)
        
        # S·ª¨A L·ªñI: D√πng h√†m clean_json
        json_text = clean_json_response(response.text)
        if not json_text:
            print("‚ùå Kh√¥ng t√¨m th·∫•y JSON trong output AI")
            print("Raw response:", response.text[:400])
            raise HTTPException(status_code=500, detail="AI tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá")

        try:
            result = json.loads(json_text)
        except json.JSONDecodeError as e:
            print("‚ùå JSON decode error:", e)
            print("JSON extracted:", json_text[:400])
            raise HTTPException(status_code=500, detail="AI tr·∫£ v·ªÅ JSON l·ªói")

        return result
        
    except Exception as e:
        print(f"‚ùå Analyze test result error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"L·ªói: {str(e)}")


@app.post("/api/generate-adaptive-test")
async def handle_generate_adaptive_test(request: GenerateAdaptiveTestInput):
    """
    T·∫°o ƒë·ªÅ thi th√≠ch ·ª©ng d·ª±a tr√™n ƒëi·ªÉm y·∫øu c·ªßa h·ªçc sinh
    """
    try:
        print(f"üìù Generating adaptive test for user: {request.userId}")
        print(f"Weak topics: {request.weakTopics}")
        
        generation_config = {
            "temperature": 0.6,
            "response_mime_type": "application/json",
        }
        
        model = genai.GenerativeModel(
            'gemini-2.5-flash',
            generation_config=generation_config,
            system_instruction=TEST_SYSTEM_INSTRUCTION
        )
        
        topics_str = ", ".join(request.weakTopics)
        
        # --- PROMPT N√ÄY ƒê√É T·ªêT (GI·ªÆ NGUY√äN) ---
        prompt = f"""T·∫°o ƒë·ªÅ ki·ªÉm tra TO√ÅN L·ªöP 12 t·∫≠p trung v√†o c√°c ch·ªß ƒë·ªÅ Y·∫æU c·ªßa h·ªçc sinh:

**C√ÅC CH·ª¶ ƒê·ªÄ C·∫¶N LUY·ªÜN T·∫¨P:**
{topics_str}

ƒê·ªô kh√≥: {request.difficulty}

**Y√äU C·∫¶U ƒê·∫∂C BI·ªÜT:**
- 70% c√¢u h·ªèi v·ªÅ c√°c ch·ªß ƒë·ªÅ y·∫øu ƒë√£ li·ªát k√™
- 30% c√¢u h·ªèi t·ªïng h·ª£p ƒë·ªÉ ki·ªÉm tra ki·∫øn th·ª©c t·ªïng qu√°t
- ƒê·ªô kh√≥ tƒÉng d·∫ßn t·ª´ c√¢u d·ªÖ ƒë·∫øn kh√≥
- C√°c c√¢u h·ªèi ph·∫£i c√≥ ƒë·∫ßy ƒë·ªß d·ªØ li·ªáu (ph∆∞∆°ng tr√¨nh, h√†m s·ªë, s·ªë li·ªáu...)

{TEST_SYSTEM_INSTRUCTION}

***QUAN TR·ªåNG V·ªÄ JSON (B·∫ÆT BU·ªòC):***
To√†n b·ªô ƒë·∫ßu ra l√† m·ªôt chu·ªói JSON. Do ƒë√≥, t·∫•t c·∫£ c√°c k√Ω t·ª± g·∫°ch ch√©o ng∆∞·ª£c (\\) B√äN TRONG chu·ªói (v√≠ d·ª•: trong LaTeX) PH·∫¢I ƒë∆∞·ª£c tho√°t (escaped) b·∫±ng c√°ch nh√¢n ƒë√¥i.
V√ç D·ª§:
- SAI: "$\\frac{{1}}{{2}}$"
- ƒê√öNG: "$\\\\frac{{1}}{{2}}$"
- SAI: "$\\lim_{{x \\to 0}}$"
- ƒê√öNG: "$\\\\lim_{{x \\\\to 0}}$"
- SAI: "$(1; +\\infty)$"
- ƒê√öNG: "$(1; +\\\\infty)$"

L∆ØU √ù B·∫ÆT BU·ªòC:
- KH√îNG d√πng markdown ```json ... ```
- T·∫§T C·∫¢ D·∫§U \\ TRONG LATEX PH·∫¢I ƒê∆Ø·ª¢C ESCAPE (v√≠ d·ª•: \\\\frac, \\\\lim, \\\\infty)

Tr·∫£ v·ªÅ JSON thu·∫ßn t√∫y (KH√îNG d√πng markdown code block)."""
        
        response = model.generate_content(prompt)
        
        # --- S·ª¨A L·ªñI 2C: B·ªî SUNG PARSING JSON AN TO√ÄN ---
        try:
            json_text = clean_json_response(response.text)
            if not json_text:
                raise ValueError("Kh√¥ng t√¨m th·∫•y JSON h·ª£p l·ªá")
            result = json.loads(json_text)
        except json.JSONDecodeError as e:
            print(f"‚ùå JSON parse error: {e}")
            raise HTTPException(status_code=500, detail="AI tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá")
        
        return {
            "userId": request.userId,
            "weakTopics": request.weakTopics,
            "difficulty": request.difficulty,
            "test": result
        }
        
    except Exception as e:
        print(f"‚ùå Generate adaptive test error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    print("\n" + "="*60)
    print("üöÄ Starting Math Tutor API Server")
    print("="*60)
    print(f"üìÅ Exercises folder: {EXERCISES_FOLDER}")
    print(f"üìÅ Tests folder: {TESTS_FOLDER}")
    print("\nüìÑ Supported formats: PDF (.pdf), Word (.docx, .doc)")
    print("‚ö†Ô∏è  NOTE: Place your files in these folders")
    print("="*60 + "\n")
    

    uvicorn.run(app, host="0.0.0.0", port=8000)
