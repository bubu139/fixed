# src/ai_flows/chat_flow.py
import asyncio
import os
import tempfile
import httpx 
from typing import AsyncGenerator
from ..ai_schemas.chat_schema import ChatInputSchema
from ..ai_config import genai 
from ..services.audio_service import transcribe_audio # Import service

MODEL_NAME = "gemini-2.5-flash" # Khuy√™n d√πng 1.5 Flash v√¨ ·ªïn ƒë·ªãnh h∆°n b·∫£n 2.5/Experimental


SYSTEM_INSTRUCTION = SYSTEM_INSTRUCTION = """
B·∫°n l√† m·ªôt AI gia s∆∞ to√°n h·ªçc THPT l·ªõp 12 Vi·ªát Nam t√¢m huy·∫øt v√† chuy√™n nghi·ªáp.
Tri·∫øt l√Ω: "Kh√¥ng gi·∫£i b√†i thay h·ªçc sinh, m√† trang b·ªã t∆∞ duy ƒë·ªÉ h·ªçc sinh T·ª∞ TIN gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ."

QUY TR√åNH H∆Ø·ªöNG D·∫™N (Th·ª±c hi·ªán tu·∫ßn t·ª±):

1. **PH√ÇN T√çCH & TR·ª∞C QUAN H√ìA (B∆∞·ªõc ƒë·∫ßu ti√™n):**
   - ƒê·ªçc k·ªπ ƒë·ªÅ b√†i.
   - N·∫øu b√†i to√°n thu·ªôc d·∫°ng **H√¨nh h·ªçc** (Kh√¥ng gian, Oxyz) ho·∫∑c **H√†m s·ªë** (ƒê·ªì th·ªã, t∆∞∆°ng giao), b·∫°n PH·∫¢I t·∫°o l·ªánh v·∫Ω h√¨nh minh h·ªça.
   - S·ª≠ d·ª•ng tr∆∞·ªùng `geogebra` trong output ƒë·ªÉ g·ª≠i l·ªánh v·∫Ω.

2. **ƒê·ªäNH H∆Ø·ªöNG T∆Ø DUY (Orientation):**
   - Tuy·ªát ƒë·ªëi KH√îNG ƒë∆∞a ra l·ªùi gi·∫£i ngay.
   - B·∫Øt ƒë·∫ßu b·∫±ng b·ªô c√¢u h·ªèi k√≠ch th√≠ch t∆∞ duy (Flow Thinking):
     + "ƒê·ªÅ b√†i y√™u c·∫ßu t√¨m g√¨?" (Goal)
     + "Ta c√≥ nh·ªØng d·ªØ ki·ªán/gi·∫£ thi·∫øt n√†o?" (Input)
     + "ƒê·ªÉ t√¨m A ta c·∫ßn bi·∫øt B, ƒë·ªÉ c√≥ B ta c·∫ßn C..." (T∆∞ duy ng∆∞·ª£c - Reverse Engineering).
     + "Em nghƒ© ta n√™n t·∫≠p trung v√†o y·∫øu t·ªë n√†o?"

3. **R√Ä SO√ÅT KI·∫æN TH·ª®C (Knowledge Check & Mindmap):**
   - X√°c ƒë·ªãnh b√†i to√°n n√†y c·∫ßn nh·ªØng ki·∫øn th·ª©c SGK n√†o (v√≠ d·ª•: C√¥ng th·ª©c t√≠nh th·ªÉ t√≠ch, ƒê·∫°o h√†m h√†m h·ª£p, v.v.).
   - Ki·ªÉm tra xem h·ªçc sinh ƒë√£ n·∫Øm v·ªØng ch∆∞a.
   - N·∫øu ph√°t hi·ªán h·ªçc sinh h·ªïng ki·∫øn th·ª©c:
     + Gi·∫£i th√≠ch ng·∫Øn g·ªçn l·∫°i l√Ω thuy·∫øt.
     + T·∫†O NODE MINDMAP M·ªöI (s·ª≠ d·ª•ng tr∆∞·ªùng `mindmap_insights`): Ghi l·∫°i ki·∫øn th·ª©c n√†y nh∆∞ m·ªôt "concept" c·∫ßn √¥n t·∫≠p.
   - N·∫øu h·ªçc sinh ƒë√£ n·∫Øm v·ªØng ƒë∆∞·ª£c ki·∫øn th·ª©c: chuy·ªÉn sang b∆∞·ªõc l√†m ti·∫øp theo.

4. **H∆Ø·ªöNG D·∫™N GI·∫¢I QUY·∫æT (Step-by-step Execution):**
   - Chia nh·ªè b√†i to√°n th√†nh c√°c b∆∞·ªõc. H∆∞·ªõng d·∫´n h·ªçc sinh ƒëi t·ª´ng b∆∞·ªõc m·ªôt( h·ªçc sinh s·∫Ω tr·∫£ l·ªùi h∆∞·ªõng gi·∫£i, kh√¥ng tr·∫£ l·ªùi chi ti·∫øt t·ª´ng b∆∞·ªõc )
   - Ki·ªÉm tra input c·ªßa h·ªçc sinh:
     + N·∫øu sai: Ch·ªâ ra l·ªói sai logic/t√≠nh to√°n c·ª• th·ªÉ. Y√™u c·∫ßu l√†m l·∫°i.
     + N·∫øu ƒë√∫ng: X√°c nh·∫≠n v√† g·ª£i √Ω b∆∞·ªõc ti·∫øp theo.
   - Ch·ªâ cung c·∫•p l·ªùi gi·∫£i chi ti·∫øt (Solution) khi h·ªçc sinh ƒë√£ n·ªó l·ª±c h·∫øt s·ª©c m√† v·∫´n b·∫ø t·∫Øc.

5. **T·ªîNG K·∫æT:**
   - Khi ra ƒë√°p √°n ƒë√∫ng: Khen ng·ª£i v√† ch·ªët l·∫°i ph∆∞∆°ng ph√°p t∆∞ duy ƒë√£ d√πng.

ƒê·ªäNH D·∫†NG ƒê·∫¶U RA (JSON B·∫ÆT BU·ªòC):
B·∫°n ph·∫£i tr·∫£ v·ªÅ JSON kh·ªõp v·ªõi schema sau:
{
  "reply": "N·ªôi dung l·ªùi tho·∫°i th√¢n thi·ªán (Markdown). Ch·ª©a l·ªùi gi·∫£i th√≠ch, c√¢u h·ªèi g·ª£i m·ªü...",
  "mindmap_insights": [
    {
      "node_id": "slug-ten-kien-thuc",
      "label": "T√™n ki·∫øn th·ª©c b·ªã h·ªïng",
      "type": "concept",
      "weakness_summary": "H·ªçc sinh qu√™n c√¥ng th·ª©c...",
      "action_steps": ["√în t·∫≠p l·∫°i SGK trang..."]
    }
  ],
  "geogebra": {
    "should_draw": true,
    "reason": "V·∫Ω ƒë·ªì th·ªã h√†m s·ªë ƒë·ªÉ x√©t t√≠nh ƒë∆°n ƒëi·ªáu",
    "commands": ["f(x) = x^3 - 3x", "A=(1, -2)"]
  }
}
"""


async def download_file_from_url(url: str) -> str:
    """T·∫£i file t·ª´ URL v·ªÅ th∆∞ m·ª•c t·∫°m"""
    try:
        async with httpx.AsyncClient() as client:
            resp = await client.get(url)
            resp.raise_for_status()
            
            # L·∫•y ƒëu√¥i file ho·∫∑c m·∫∑c ƒë·ªãnh mp3
            ext = os.path.splitext(url)[1] or ".mp3"
            if "?" in ext: ext = ext.split("?")[0]
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                tmp.write(resp.content)
                return tmp.name
    except Exception as e:
        print(f"‚ùå Error downloading file: {e}")
        return None

async def chat(input: ChatInputSchema) -> AsyncGenerator[str, None]:
    # 1. C·∫•u h√¨nh Model
    generation_config = {
        "temperature": 0.7,
        "max_output_tokens": 8192,
        "response_mime_type": "application/json",
    }

    model = genai.GenerativeModel(
        model_name=MODEL_NAME,
        generation_config=generation_config,
        system_instruction=SYSTEM_INSTRUCTION
    )

    # 2. History
    gemini_history = []
    if input.history:
        for turn in input.history:
            role = "model" if turn.role == "assistant" else "user"
            gemini_history.append({
                "role": role,
                "parts": [{"text": turn.content}]
            })

    # 3. X·ª¨ L√ù MESSAGE & AUDIO
    user_parts = []
    msg_text = input.message
    temp_files_to_delete = []

    if input.media:
        for media in input.media:
            # N·∫øu l√† Audio -> T·∫£i v·ªÅ & Transcribe
            if media.type and media.type.startswith("audio/"):
                print(f"üé§ Detected audio: {media.url}")
                local_path = await download_file_from_url(media.url)
                
                if local_path:
                    temp_files_to_delete.append(local_path)
                    # G·ªçi service chuy·ªÉn ƒë·ªïi
                    transcript = await transcribe_audio(local_path, mime_type=media.type)
                    print(f"üìù Transcript: {transcript}")
                    
                    # N·ªëi n·ªôi dung v√†o tin nh·∫Øn cho AI ƒë·ªçc
                    msg_text += f"\n\n[H·ªçc sinh g·ª≠i ghi √¢m: \"{transcript}\"]"
                else:
                    msg_text += f"\n[L·ªói t·∫£i file ghi √¢m]"
            
            # N·∫øu l√† ·∫¢nh -> G·ª≠i tr·ª±c ti·∫øp url (Gemini h·ªó tr·ª£ ·∫£nh qua url n·∫øu config ƒë√∫ng, 
            # nh∆∞ng t·ªët nh·∫•t v·∫´n n√™n t·∫£i v·ªÅ n·∫øu g·∫∑p l·ªói permission. 
            # ·ªû ƒë√¢y t·∫°m gi·ªØ logic c≈© cho ·∫£nh)
            else:
                 user_parts.append({"text": f"[User sent media: {media.url}]"})

    user_parts.append({"text": msg_text})

    # 4. G·ª≠i & Stream
    try:
        chat_session = model.start_chat(history=gemini_history)
        response = await chat_session.send_message_async(user_parts, stream=True)

        async for chunk in response:
            if chunk.text:
                yield chunk.text

    finally:
        # D·ªçn d·∫πp file t·∫°m local
        for path in temp_files_to_delete:
            if os.path.exists(path):
                os.remove(path)
